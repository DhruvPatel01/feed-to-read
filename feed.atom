<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
    <id>urn:2023-10-15T00:55:27.242Z</id>
    <title>osmos::feed</title>
    <updated>2023-10-15T00:55:27.242Z</updated>
    <generator>osmosfeed 1.15.1</generator>
    <link rel="alternate" href="index.html"/>
    <entry>
        <title type="html"><![CDATA[LSP could have been better]]></title>
        <id>https://matklad.github.io/2023/10/12/lsp-could-have-been-better.html</id>
        <link href="https://matklad.github.io/2023/10/12/lsp-could-have-been-better.html"/>
        <updated>2023-10-12T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[We talk about programming like it is about writing code, but the code ends up being less important
than the architecture, and the architecture ends up being less important than social issues.]]></summary>
        <author>
            <name>matklad</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Version 1.6.16 released]]></title>
        <id>https://nim-lang.org//blog/2023/10/11/version-1616-released.html</id>
        <link href="https://nim-lang.org//blog/2023/10/11/version-1616-released.html"/>
        <updated>2023-10-11T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[The Nim team is happy to announce version 1.6.16, our eight patch release for
Nim 1.6.
Version 1.6.16 is a result of three months of hard work, and it contains
84 commits,
bringing lots of general improvements over 1.6.14.
This release is aimed at our users who haven’t switched to Nim v2.0 yet.
Installing Nim 1.6
New users
Check out if the package manager of your OS already ships version 1.6.16 or
install it as described here.
Existing users
If you have installed a previous version of Nim using choosenim,
getting Nim 1.6.16 is as easy as:
$ choosenim 1.6.16

Alternatively, you can download Nim 1.6.16 from
our nightlies builds.
Donating to Nim
We would like to encourage you to donate to Nim.
The donated money will be used to further improve Nim by creating bounties
for the most important bu…]]></summary>
        <author>
            <name>Nim Programming Language</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[UNIX Structured Concurrency]]></title>
        <id>https://matklad.github.io/2023/10/11/unix-structured-concurrency.html</id>
        <link href="https://matklad.github.io/2023/10/11/unix-structured-concurrency.html"/>
        <updated>2023-10-11T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[A short note on a particular structured concurrency pattern for UNIX systems programming.]]></summary>
        <author>
            <name>matklad</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[My personal C coding style as of late 2023]]></title>
        <id>https://nullprogram.com/blog/2023/10/08/</id>
        <link href="https://nullprogram.com/blog/2023/10/08/"/>
        <updated>2023-10-08T23:30:57.000Z</updated>
        <summary type="html"><![CDATA[This article was discussed on Hacker News and on reddit.
This has been a ground-breaking year for my C skills, and paradigm shifts
in my technique has provoked me to reconsider my habits and coding style.
It’s been my largest personal style change in years, so I’ve decided to
take a snapshot of its current state and my reasoning. These changes have
produced significant productive and organizational benefits, so while most
is certainly subjective, it likely includes a few objective improvements.
I’m not saying everyone should write C this way, and when I contribute
code to a project I follow their local style. This is about what works
well for me.
Primitive types
Starting with the fundamentals, I’ve been using short names for primitive
types. The resulting clarity was more than I had expect…]]></summary>
        <author>
            <name>null program</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Web server ‘hello world’ benchmark : Go vs Node.js vs Nim vs Bun]]></title>
        <id>https://lemire.me/blog/?p=20845</id>
        <link href="https://lemire.me/blog/2023/10/07/web-server-hello-world-benchmark-go-vs-node-js-vs-nim-vs-bun/"/>
        <updated>2023-10-07T05:43:25.000Z</updated>
        <summary type="html"><![CDATA[There are many popular frameworks for writing little web applications. Go and JavaScript (Node.js) are among the most popular choices. Reportedly, Netflix runs on Node.js; Uber moved from Node.js to Go for better performance. There are also less popular options such as Nim. An in-depth review of their performance characteristics would be challenging.  But I … Continue reading Web server ‘hello world’ benchmark : Go vs Node.js vs Nim vs Bun]]></summary>
        <author>
            <name>Daniel Lemire</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Interesting]]></title>
        <id>https://apenwarr.ca/log/20231006</id>
        <link href="https://apenwarr.ca/log/20231006"/>
        <updated>2023-10-06T20:59:31.000Z</updated>
        <summary type="html"><![CDATA[A few conversations last week made me realize I use the word “interesting” in an unusual way.
I rely heavily on mental models. Of course, everyone relies on mental models. But I do it intentionally and I push it extra hard.
What I mean by that is, when I’m making predictions about what will happen next, I mostly don’t look around me and make a judgement based on my immediate surroundings. Instead, I look at what I see, try to match it to something inside my mental model, and then let the mental model extrapolate what “should” happen from there.
If this sounds predictably error prone: yes. It is.
But it’s also powerful, when used the right way, which I try to do. Here’s my system.
Confirmation bias
First of all, let’s acknowledge the problem with mental models: confirmation bias. Confirmati…]]></summary>
        <author>
            <name>apenwarr</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[What is an Invariant?]]></title>
        <id>https://matklad.github.io/2023/10/06/what-is-an-invariant.html</id>
        <link href="https://matklad.github.io/2023/10/06/what-is-an-invariant.html"/>
        <updated>2023-10-06T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[I extolled the benefits of programming with invariants in a couple of recent posts.
Naturally, I didn't explain what I think when I write invariant. This post fixes that.]]></summary>
        <author>
            <name>matklad</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[A simple, arena-backed, generic dynamic array for C]]></title>
        <id>https://nullprogram.com/blog/2023/10/05/</id>
        <link href="https://nullprogram.com/blog/2023/10/05/"/>
        <updated>2023-10-05T23:05:57.000Z</updated>
        <summary type="html"><![CDATA[Previously I presented an arena-friendly hash map applicable to any
programming language where one might use arena allocation. In this third
article I present a generic, arena-backed dynamic array. The details are
specific to C, as the most appropriate mechanism depends on the language
(e.g. templates, generics). Just as in the previous two articles, the goal
is to demonstrate an idea so simple that a full implementation fits on one
terminal pager screen — a concept rather than a library.
Unlike a hash map or linked list, a dynamic array — a data buffer with a
size that varies during run time — is more difficult to square with arena
allocation. They’re contiguous by definition, and we cannot resize objects
in the middle of an arena, i.e. realloc. So while convenient, they come
with trade-o…]]></summary>
        <author>
            <name>null program</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[An easy-to-implement, arena-friendly hash map]]></title>
        <id>https://nullprogram.com/blog/2023/09/30/</id>
        <link href="https://nullprogram.com/blog/2023/09/30/"/>
        <updated>2023-09-30T23:18:40.000Z</updated>
        <summary type="html"><![CDATA[My last article had tips for for arena allocation. This next
article demonstrates a technique for building bespoke hash maps that
compose nicely with arena allocation. In addition, they’re fast, simple,
and automatically scale to any problem that could reasonably be solved
with an in-memory hash map. To avoid resizing — both to better support
arenas and to simplify implementation — they have slightly above average
memory requirements. The design, which we’re calling a hash-trie, is the
result of fruitful collaboration with NRK, whose sibling article
includes benchmarks. It’s my new favorite data structure, and has proven
incredibly useful. With a couple well-placed acquire/release atomics, we
can even turn it into a lock-free concurrent hash map.
I’ve written before about MSI hash tables, …]]></summary>
        <author>
            <name>null program</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Arena allocator tips and tricks]]></title>
        <id>https://nullprogram.com/blog/2023/09/27/</id>
        <link href="https://nullprogram.com/blog/2023/09/27/"/>
        <updated>2023-09-27T03:58:59.000Z</updated>
        <summary type="html"><![CDATA[This article was discussed on Hacker News.
Over the past year I’ve refined my approach to arena allocation.
With practice, it’s effective, simple, and fast; typically as easy to use
as garbage collection but without the costs. Depending on need, an
allocator can weigh just 7–25 lines of code — perfect when lacking a
runtime. With the core details of my own technique settled, now is a
good time to document and share lessons learned. This is certainly not the
only way to approach arena allocation, but these are practices I’ve worked
out to simplify programs and reduce mistakes.
An arena is a memory buffer and an offset into that buffer, initially
zero. To allocate an object, grab a pointer at the offset, advance the
offset by the size of the object, and return the pointer. There’s a little
m…]]></summary>
        <author>
            <name>null program</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Parsing integers quickly with AVX-512]]></title>
        <id>https://lemire.me/blog/?p=20836</id>
        <link href="https://lemire.me/blog/2023/09/22/parsing-integers-quickly-with-avx-512/"/>
        <updated>2023-09-22T21:50:14.000Z</updated>
        <summary type="html"><![CDATA[If I give a programmer a string such as "9223372036854775808" and I ask them to convert it to an integer, they might do the following in C++: std::string s = .... uint64_t val; auto [ptr, ec] = std::from_chars(s.data(), s.data() + s.size(), val); if (ec != std::errc()) {} // I have an error ! // val … Continue reading Parsing integers quickly with AVX-512]]></summary>
        <author>
            <name>Daniel Lemire</name>
        </author>
    </entry>
    <entry>
        <title type="html"><![CDATA[Mastering Nim, 2nd edition]]></title>
        <id>https://nim-lang.org//blog/2023/09/19/mastering-nim.html</id>
        <link href="https://nim-lang.org//blog/2023/09/19/mastering-nim.html"/>
        <updated>2023-09-19T00:00:00.000Z</updated>
        <summary type="html"><![CDATA[Discover the secret of Nim!
The definite guide on Nim!
Written by the inventor himself.
Now with updated content for version 2.0 which solves the biggest pain point of Nim 1.0, shared memory in a multi-threaded setting.
Please have a look at its cover image:
But Nim’s logo is a crown!
Where is the crown?
That’s the secret of Nim!
Send us your reply to support@nim-lang.org until December 6th 2023.
Among the correct answers we will select 3 winners by randomization.
The winners will receive a signed hardcover!
“Mastering Nim” is available here:
amazon.com
amazon.de]]></summary>
        <author>
            <name>Nim Programming Language</name>
        </author>
    </entry>
</feed>